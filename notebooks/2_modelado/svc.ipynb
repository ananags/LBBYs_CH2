{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5ecad52",
   "metadata": {},
   "source": [
    "# Modelo SVC para detección de noticias falsas\n",
    "\n",
    "En este notebook, entrenaremos un modelo de clasificación basado en **Support Vector Classification (SVC)** para predecir si una afirmación política es **verdadera** o **falsa**.\n",
    "\n",
    "Se utilizarán técnicas de preprocesamiento de texto (TF-IDF) y metadatos categóricos (codificados y escalados). Además, se aplicará balanceo de clases con SMOTE, selección de características, y búsqueda de hiperparámetros con GridSearchCV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae200740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (from scikit-learn) (2.2.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (from imbalanced-learn) (2.2.5)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (from imbalanced-learn) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (from imbalanced-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\inesg\\dev\\lbbys_ch2\\venv\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy matplotlib seaborn\n",
    "%pip install -U scikit-learn\n",
    "%pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c983569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c295dc",
   "metadata": {},
   "source": [
    "### Carga dataset\n",
    "\n",
    "Se cargan los datasets de entrenamiento y prueba preprocesados, que contienen:\n",
    "\n",
    "- `statement`: texto de la afirmación (columna principal para NLP).\n",
    "- `subject`: tema de la afirmación (categórica).\n",
    "- `speaker`: persona que hizo la afirmación (categórica).\n",
    "- `party_affiliation`: partido político (categórica).\n",
    "- `state_info_*`: columnas relacionadas con la ubicación geográfica.\n",
    "- `label`: etiqueta binaria (0 = falso, 1 = verdadero) para entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "116400cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datasets limpios\n",
    "train_data = pd.read_csv('C:/Users/inesg/dev/LBBYs_CH2/data/processed/train_simp_preprocess_v2.csv')\n",
    "test_data = pd.read_csv('C:/Users/inesg/dev/LBBYs_CH2/data/processed/test_simp_preprocess_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aa59605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_job</th>\n",
       "      <th>state_info</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>party_affiliation_uni</th>\n",
       "      <th>party_affiliation_category_map</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_info_without_stopwords</th>\n",
       "      <th>pos_freq_without_stopwords</th>\n",
       "      <th>lemma_freq_without_stopwords</th>\n",
       "      <th>tag_freq_without_stopwords</th>\n",
       "      <th>processed_subject</th>\n",
       "      <th>speaker_entities</th>\n",
       "      <th>speaker_type</th>\n",
       "      <th>speaker_job_tokens</th>\n",
       "      <th>state_info_tokens</th>\n",
       "      <th>party_affiliation_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81f884c64a7</td>\n",
       "      <td>1</td>\n",
       "      <td>china is in the south china sea and (building)...</td>\n",
       "      <td>other</td>\n",
       "      <td>donald-trump</td>\n",
       "      <td>president-elect</td>\n",
       "      <td>new york</td>\n",
       "      <td>republican</td>\n",
       "      <td>republican</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'lemma': 'china', 'pos': 'PROPN', 'tag': 'NN...</td>\n",
       "      <td>Counter({'PROPN': 4, 'NOUN': 4, 'ADJ': 1, 'VER...</td>\n",
       "      <td>Counter({'china': 2, 'south': 1, 'sea': 1, 'bu...</td>\n",
       "      <td>Counter({'NNP': 4, 'NN': 3, 'JJ': 1, 'NNS': 1,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['donald trump']</td>\n",
       "      <td>['PERSON']</td>\n",
       "      <td>['president', '-', 'elect']</td>\n",
       "      <td>['new', 'york']</td>\n",
       "      <td>['republican']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30c2723a188</td>\n",
       "      <td>0</td>\n",
       "      <td>with the resources it takes to execute just ov...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>chris-dodd</td>\n",
       "      <td>u.s. senator</td>\n",
       "      <td>connecticut</td>\n",
       "      <td>democrat</td>\n",
       "      <td>democrat</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'lemma': 'resource', 'pos': 'NOUN', 'tag': '...</td>\n",
       "      <td>Counter({'NOUN': 7, 'VERB': 4, 'PROPN': 2, 'AD...</td>\n",
       "      <td>Counter({'resource': 1, 'take': 1, 'execute': ...</td>\n",
       "      <td>Counter({'NN': 4, 'NNS': 3, 'VB': 2, 'NNP': 2,...</td>\n",
       "      <td>['health-care']</td>\n",
       "      <td>['chris dodd']</td>\n",
       "      <td>['PERSON']</td>\n",
       "      <td>['u.s', '.', 'senator']</td>\n",
       "      <td>['connecticut']</td>\n",
       "      <td>['democrat']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6936b216e5d</td>\n",
       "      <td>0</td>\n",
       "      <td>the (wisconsin) governor has proposed tax give...</td>\n",
       "      <td>other</td>\n",
       "      <td>donna-brazile</td>\n",
       "      <td>other</td>\n",
       "      <td>washington, d.c.</td>\n",
       "      <td>democrat</td>\n",
       "      <td>democrat</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'lemma': 'wisconsin', 'pos': 'PROPN', 'tag':...</td>\n",
       "      <td>Counter({'NOUN': 4, 'PROPN': 1, 'VERB': 1})</td>\n",
       "      <td>Counter({'wisconsin': 1, 'governor': 1, 'propo...</td>\n",
       "      <td>Counter({'NN': 2, 'NNS': 2, 'NNP': 1, 'VBN': 1})</td>\n",
       "      <td>[]</td>\n",
       "      <td>['donna brazile']</td>\n",
       "      <td>['PERSON']</td>\n",
       "      <td>['other']</td>\n",
       "      <td>['washington', ',', 'd.c', '.']</td>\n",
       "      <td>['democrat']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b5cd9195738</td>\n",
       "      <td>1</td>\n",
       "      <td>says her representation of an ex-boyfriend who...</td>\n",
       "      <td>other</td>\n",
       "      <td>rebecca-bradley</td>\n",
       "      <td>non-define</td>\n",
       "      <td>non-define</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>other-political-groups</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'lemma': 'say', 'pos': 'VERB', 'tag': 'VBZ',...</td>\n",
       "      <td>Counter({'NOUN': 9, 'VERB': 1, 'ADJ': 1})</td>\n",
       "      <td>Counter({'say': 1, 'representation': 1, 'ex': ...</td>\n",
       "      <td>Counter({'NN': 8, 'VBZ': 1, 'NNS': 1, 'JJ': 1})</td>\n",
       "      <td>[]</td>\n",
       "      <td>['rebecca bradley']</td>\n",
       "      <td>['PERSON']</td>\n",
       "      <td>['non', '-', 'define']</td>\n",
       "      <td>['non', '-', 'define']</td>\n",
       "      <td>['none']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84f8dac7737</td>\n",
       "      <td>0</td>\n",
       "      <td>at protests in wisconsin against proposed coll...</td>\n",
       "      <td>other</td>\n",
       "      <td>republican-party-wisconsin</td>\n",
       "      <td>non-define</td>\n",
       "      <td>wisconsin</td>\n",
       "      <td>republican</td>\n",
       "      <td>republican</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'lemma': 'protest', 'pos': 'NOUN', 'tag': 'N...</td>\n",
       "      <td>Counter({'NOUN': 7, 'VERB': 4, 'ADJ': 3})</td>\n",
       "      <td>Counter({'protest': 1, 'wisconsin': 1, 'propos...</td>\n",
       "      <td>Counter({'NNS': 4, 'NN': 3, 'JJ': 3, 'VBN': 2,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['republican party', 'wisconsin']</td>\n",
       "      <td>['ORG', 'GPE']</td>\n",
       "      <td>['non', '-', 'define']</td>\n",
       "      <td>['wisconsin']</td>\n",
       "      <td>['republican']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  label                                          statement  \\\n",
       "0  81f884c64a7      1  china is in the south china sea and (building)...   \n",
       "1  30c2723a188      0  with the resources it takes to execute just ov...   \n",
       "2  6936b216e5d      0  the (wisconsin) governor has proposed tax give...   \n",
       "3  b5cd9195738      1  says her representation of an ex-boyfriend who...   \n",
       "4  84f8dac7737      0  at protests in wisconsin against proposed coll...   \n",
       "\n",
       "       subject                     speaker      speaker_job        state_info  \\\n",
       "0        other                donald-trump  president-elect          new york   \n",
       "1  health-care                  chris-dodd     u.s. senator       connecticut   \n",
       "2        other               donna-brazile            other  washington, d.c.   \n",
       "3        other             rebecca-bradley       non-define        non-define   \n",
       "4        other  republican-party-wisconsin       non-define         wisconsin   \n",
       "\n",
       "  party_affiliation party_affiliation_uni party_affiliation_category_map  ...  \\\n",
       "0        republican            republican          political-affiliation  ...   \n",
       "1          democrat              democrat          political-affiliation  ...   \n",
       "2          democrat              democrat          political-affiliation  ...   \n",
       "3              none                  none         other-political-groups  ...   \n",
       "4        republican            republican          political-affiliation  ...   \n",
       "\n",
       "                          pos_info_without_stopwords  \\\n",
       "0  [{'lemma': 'china', 'pos': 'PROPN', 'tag': 'NN...   \n",
       "1  [{'lemma': 'resource', 'pos': 'NOUN', 'tag': '...   \n",
       "2  [{'lemma': 'wisconsin', 'pos': 'PROPN', 'tag':...   \n",
       "3  [{'lemma': 'say', 'pos': 'VERB', 'tag': 'VBZ',...   \n",
       "4  [{'lemma': 'protest', 'pos': 'NOUN', 'tag': 'N...   \n",
       "\n",
       "                          pos_freq_without_stopwords  \\\n",
       "0  Counter({'PROPN': 4, 'NOUN': 4, 'ADJ': 1, 'VER...   \n",
       "1  Counter({'NOUN': 7, 'VERB': 4, 'PROPN': 2, 'AD...   \n",
       "2        Counter({'NOUN': 4, 'PROPN': 1, 'VERB': 1})   \n",
       "3          Counter({'NOUN': 9, 'VERB': 1, 'ADJ': 1})   \n",
       "4          Counter({'NOUN': 7, 'VERB': 4, 'ADJ': 3})   \n",
       "\n",
       "                        lemma_freq_without_stopwords  \\\n",
       "0  Counter({'china': 2, 'south': 1, 'sea': 1, 'bu...   \n",
       "1  Counter({'resource': 1, 'take': 1, 'execute': ...   \n",
       "2  Counter({'wisconsin': 1, 'governor': 1, 'propo...   \n",
       "3  Counter({'say': 1, 'representation': 1, 'ex': ...   \n",
       "4  Counter({'protest': 1, 'wisconsin': 1, 'propos...   \n",
       "\n",
       "                          tag_freq_without_stopwords processed_subject  \\\n",
       "0  Counter({'NNP': 4, 'NN': 3, 'JJ': 1, 'NNS': 1,...                []   \n",
       "1  Counter({'NN': 4, 'NNS': 3, 'VB': 2, 'NNP': 2,...   ['health-care']   \n",
       "2   Counter({'NN': 2, 'NNS': 2, 'NNP': 1, 'VBN': 1})                []   \n",
       "3    Counter({'NN': 8, 'VBZ': 1, 'NNS': 1, 'JJ': 1})                []   \n",
       "4  Counter({'NNS': 4, 'NN': 3, 'JJ': 3, 'VBN': 2,...                []   \n",
       "\n",
       "                    speaker_entities    speaker_type  \\\n",
       "0                   ['donald trump']      ['PERSON']   \n",
       "1                     ['chris dodd']      ['PERSON']   \n",
       "2                  ['donna brazile']      ['PERSON']   \n",
       "3                ['rebecca bradley']      ['PERSON']   \n",
       "4  ['republican party', 'wisconsin']  ['ORG', 'GPE']   \n",
       "\n",
       "            speaker_job_tokens                state_info_tokens  \\\n",
       "0  ['president', '-', 'elect']                  ['new', 'york']   \n",
       "1      ['u.s', '.', 'senator']                  ['connecticut']   \n",
       "2                    ['other']  ['washington', ',', 'd.c', '.']   \n",
       "3       ['non', '-', 'define']           ['non', '-', 'define']   \n",
       "4       ['non', '-', 'define']                    ['wisconsin']   \n",
       "\n",
       "  party_affiliation_tokens  \n",
       "0           ['republican']  \n",
       "1             ['democrat']  \n",
       "2             ['democrat']  \n",
       "3                 ['none']  \n",
       "4           ['republican']  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe381c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_job</th>\n",
       "      <th>state_info</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>party_affiliation_uni</th>\n",
       "      <th>party_affiliation_category_map</th>\n",
       "      <th>statement_tokens</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_info_without_stopwords</th>\n",
       "      <th>pos_freq_without_stopwords</th>\n",
       "      <th>lemma_freq_without_stopwords</th>\n",
       "      <th>tag_freq_without_stopwords</th>\n",
       "      <th>processed_subject</th>\n",
       "      <th>speaker_entities</th>\n",
       "      <th>speaker_type</th>\n",
       "      <th>speaker_job_tokens</th>\n",
       "      <th>state_info_tokens</th>\n",
       "      <th>party_affiliation_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dc32e5ffa8b</td>\n",
       "      <td>five members of [the common cause georgia] boa...</td>\n",
       "      <td>other</td>\n",
       "      <td>kasim-reed</td>\n",
       "      <td>non-define</td>\n",
       "      <td>non-define</td>\n",
       "      <td>democrat</td>\n",
       "      <td>democrat</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>five members of [ the common cause georgia ] b...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'lemma': 'member', 'pos': 'NOUN', 'tag': 'NN...</td>\n",
       "      <td>Counter({'NOUN': 5, 'ADJ': 2, 'PROPN': 1, 'VER...</td>\n",
       "      <td>Counter({'member': 1, 'common': 1, 'cause': 1,...</td>\n",
       "      <td>Counter({'NN': 3, 'NNS': 2, 'JJ': 2, 'NNP': 1,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['PERSON']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['non', '-', 'define']</td>\n",
       "      <td>['non', '-', 'define']</td>\n",
       "      <td>['democrat']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa49bb41cab</td>\n",
       "      <td>theres no negative advertising in my campaign ...</td>\n",
       "      <td>elections</td>\n",
       "      <td>bill-mccollum</td>\n",
       "      <td>non-define</td>\n",
       "      <td>florida</td>\n",
       "      <td>republican</td>\n",
       "      <td>republican</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>there s no negative advertising in my campaign...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'lemma': 's', 'pos': 'VERB', 'tag': 'VBZ', '...</td>\n",
       "      <td>Counter({'NOUN': 2, 'VERB': 1, 'ADJ': 1})</td>\n",
       "      <td>Counter({'s': 1, 'negative': 1, 'advertising':...</td>\n",
       "      <td>Counter({'NN': 2, 'VBZ': 1, 'JJ': 1})</td>\n",
       "      <td>['elections']</td>\n",
       "      <td>['bill mccollum']</td>\n",
       "      <td>['PERSON']</td>\n",
       "      <td>['non', '-', 'define']</td>\n",
       "      <td>['florida']</td>\n",
       "      <td>['republican']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dddc8d12ac1</td>\n",
       "      <td>leticia van de putte voted to give illegal imm...</td>\n",
       "      <td>other</td>\n",
       "      <td>dan-patrick</td>\n",
       "      <td>other</td>\n",
       "      <td>texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>republican</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>leticia van de putte voted to give illegal imm...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'lemma': 'leticia', 'pos': 'PROPN', 'tag': '...</td>\n",
       "      <td>Counter({'NOUN': 10, 'ADJ': 4, 'PROPN': 2, 'X'...</td>\n",
       "      <td>Counter({'health': 3, 'care': 3, 'free': 2, 'l...</td>\n",
       "      <td>Counter({'NN': 9, 'JJ': 4, 'NNP': 2, 'FW': 1, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['dan patrick']</td>\n",
       "      <td>['PERSON']</td>\n",
       "      <td>['other']</td>\n",
       "      <td>['texas']</td>\n",
       "      <td>['republican']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bcfe8f51667</td>\n",
       "      <td>fiorinas plan would mean slashing social secur...</td>\n",
       "      <td>other</td>\n",
       "      <td>barbara-boxer</td>\n",
       "      <td>u.s. senator</td>\n",
       "      <td>california</td>\n",
       "      <td>democrat</td>\n",
       "      <td>democrat</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>fiorinas plan would mean slashing social secur...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'lemma': 'fiorina', 'pos': 'NOUN', 'tag': 'N...</td>\n",
       "      <td>Counter({'NOUN': 4, 'VERB': 2, 'ADJ': 1})</td>\n",
       "      <td>Counter({'fiorina': 1, 'plan': 1, 'mean': 1, '...</td>\n",
       "      <td>Counter({'NN': 3, 'NNS': 1, 'VB': 1, 'VBG': 1,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['barbara boxer']</td>\n",
       "      <td>['PERSON']</td>\n",
       "      <td>['u.s', '.', 'senator']</td>\n",
       "      <td>['california']</td>\n",
       "      <td>['democrat']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eedbbaff5ab</td>\n",
       "      <td>by the end of his first term, president obama ...</td>\n",
       "      <td>other</td>\n",
       "      <td>mitt-romney</td>\n",
       "      <td>former governor</td>\n",
       "      <td>massachusetts</td>\n",
       "      <td>republican</td>\n",
       "      <td>republican</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>by the end of his first term , president obama...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'lemma': 'end', 'pos': 'NOUN', 'tag': 'NN', ...</td>\n",
       "      <td>Counter({'NOUN': 4, 'PROPN': 2, 'VERB': 2, 'AD...</td>\n",
       "      <td>Counter({'president': 2, 'end': 1, 'term': 1, ...</td>\n",
       "      <td>Counter({'NN': 3, 'NNP': 2, 'VBN': 2, 'JJ': 1,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['mitt romney']</td>\n",
       "      <td>['PERSON']</td>\n",
       "      <td>['former', 'governor']</td>\n",
       "      <td>['massachusetts']</td>\n",
       "      <td>['republican']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                          statement    subject  \\\n",
       "0  dc32e5ffa8b  five members of [the common cause georgia] boa...      other   \n",
       "1  aa49bb41cab  theres no negative advertising in my campaign ...  elections   \n",
       "2  dddc8d12ac1  leticia van de putte voted to give illegal imm...      other   \n",
       "3  bcfe8f51667  fiorinas plan would mean slashing social secur...      other   \n",
       "4  eedbbaff5ab  by the end of his first term, president obama ...      other   \n",
       "\n",
       "         speaker      speaker_job     state_info party_affiliation  \\\n",
       "0     kasim-reed       non-define     non-define          democrat   \n",
       "1  bill-mccollum       non-define        florida        republican   \n",
       "2    dan-patrick            other          texas        republican   \n",
       "3  barbara-boxer     u.s. senator     california          democrat   \n",
       "4    mitt-romney  former governor  massachusetts        republican   \n",
       "\n",
       "  party_affiliation_uni party_affiliation_category_map  \\\n",
       "0              democrat          political-affiliation   \n",
       "1            republican          political-affiliation   \n",
       "2            republican          political-affiliation   \n",
       "3              democrat          political-affiliation   \n",
       "4            republican          political-affiliation   \n",
       "\n",
       "                                    statement_tokens  ...  \\\n",
       "0  five members of [ the common cause georgia ] b...  ...   \n",
       "1  there s no negative advertising in my campaign...  ...   \n",
       "2  leticia van de putte voted to give illegal imm...  ...   \n",
       "3  fiorinas plan would mean slashing social secur...  ...   \n",
       "4  by the end of his first term , president obama...  ...   \n",
       "\n",
       "                          pos_info_without_stopwords  \\\n",
       "0  [{'lemma': 'member', 'pos': 'NOUN', 'tag': 'NN...   \n",
       "1  [{'lemma': 's', 'pos': 'VERB', 'tag': 'VBZ', '...   \n",
       "2  [{'lemma': 'leticia', 'pos': 'PROPN', 'tag': '...   \n",
       "3  [{'lemma': 'fiorina', 'pos': 'NOUN', 'tag': 'N...   \n",
       "4  [{'lemma': 'end', 'pos': 'NOUN', 'tag': 'NN', ...   \n",
       "\n",
       "                          pos_freq_without_stopwords  \\\n",
       "0  Counter({'NOUN': 5, 'ADJ': 2, 'PROPN': 1, 'VER...   \n",
       "1          Counter({'NOUN': 2, 'VERB': 1, 'ADJ': 1})   \n",
       "2  Counter({'NOUN': 10, 'ADJ': 4, 'PROPN': 2, 'X'...   \n",
       "3          Counter({'NOUN': 4, 'VERB': 2, 'ADJ': 1})   \n",
       "4  Counter({'NOUN': 4, 'PROPN': 2, 'VERB': 2, 'AD...   \n",
       "\n",
       "                        lemma_freq_without_stopwords  \\\n",
       "0  Counter({'member': 1, 'common': 1, 'cause': 1,...   \n",
       "1  Counter({'s': 1, 'negative': 1, 'advertising':...   \n",
       "2  Counter({'health': 3, 'care': 3, 'free': 2, 'l...   \n",
       "3  Counter({'fiorina': 1, 'plan': 1, 'mean': 1, '...   \n",
       "4  Counter({'president': 2, 'end': 1, 'term': 1, ...   \n",
       "\n",
       "                          tag_freq_without_stopwords processed_subject  \\\n",
       "0  Counter({'NN': 3, 'NNS': 2, 'JJ': 2, 'NNP': 1,...                []   \n",
       "1              Counter({'NN': 2, 'VBZ': 1, 'JJ': 1})     ['elections']   \n",
       "2  Counter({'NN': 9, 'JJ': 4, 'NNP': 2, 'FW': 1, ...                []   \n",
       "3  Counter({'NN': 3, 'NNS': 1, 'VB': 1, 'VBG': 1,...                []   \n",
       "4  Counter({'NN': 3, 'NNP': 2, 'VBN': 2, 'JJ': 1,...                []   \n",
       "\n",
       "    speaker_entities speaker_type       speaker_job_tokens  \\\n",
       "0         ['PERSON']           []   ['non', '-', 'define']   \n",
       "1  ['bill mccollum']   ['PERSON']   ['non', '-', 'define']   \n",
       "2    ['dan patrick']   ['PERSON']                ['other']   \n",
       "3  ['barbara boxer']   ['PERSON']  ['u.s', '.', 'senator']   \n",
       "4    ['mitt romney']   ['PERSON']   ['former', 'governor']   \n",
       "\n",
       "        state_info_tokens  party_affiliation_tokens  \n",
       "0  ['non', '-', 'define']              ['democrat']  \n",
       "1             ['florida']            ['republican']  \n",
       "2               ['texas']            ['republican']  \n",
       "3          ['california']              ['democrat']  \n",
       "4       ['massachusetts']            ['republican']  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bee942",
   "metadata": {},
   "source": [
    "### Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a1057d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_folder = \"C:/Users/inesg/dev/LBBYs_CH2/notebooks/3_summision\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a417ea1b",
   "metadata": {},
   "source": [
    "### Preprocesamiento de los datos\n",
    "#### 1. Preprocesamiento del texto con TF-IDF\n",
    "Se transforma la columna `statement` con TF-IDF, limitando a las 1000 palabras más importantes y eliminando stopwords en inglés.\n",
    "\n",
    "Esto convierte el texto en vectores numéricos que el modelo puede procesar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aae622a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar el tokenizer con TF-IDF\n",
    "tokenizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X_text = tokenizer.fit_transform(train_data['statement']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce83818",
   "metadata": {},
   "source": [
    "#### 2. Preprocesamiento de metadatos\n",
    "Se codifican las variables categóricas (`subject`, `speaker`, `party_affiliation`) con LabelEncoder y se reduce la información de `state_info_*` a un indicador binario de presencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2762026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_subject = LabelEncoder()\n",
    "label_encoder_speaker = LabelEncoder()\n",
    "label_encoder_party = LabelEncoder()\n",
    "\n",
    "train_data['subject_encoded'] = label_encoder_subject.fit_transform(train_data['subject'])\n",
    "train_data['speaker_encoded'] = label_encoder_speaker.fit_transform(train_data['speaker'])\n",
    "\n",
    "state_info_columns = [col for col in train_data.columns if col.startswith('state_info')]\n",
    "train_data['state_info_encoded'] = train_data[state_info_columns].apply(\n",
    "    lambda x: 1 if any(isinstance(val, str) and len(val) > 0 for val in x) else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "train_data['party_affiliation_encoded'] = label_encoder_party.fit_transform(train_data['party_affiliation'])\n",
    "\n",
    "X_metadata = train_data[['subject_encoded', 'speaker_encoded', 'state_info_encoded', 'party_affiliation_encoded']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026119c6",
   "metadata": {},
   "source": [
    "#### 3. Escalar los metadatos\n",
    "Se normalizan los valores numéricos de los metadatos para que estén en la misma escala y el modelo no se sesgue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2674bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_metadata_scaled = scaler.fit_transform(X_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed68930",
   "metadata": {},
   "source": [
    "#### 4. Unión texto y metadatos\n",
    "Se concatenan las características textuales y los metadatos para formar la matriz de características completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f64435",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = np.concatenate([X_text, X_metadata_scaled], axis=1)\n",
    "y = train_data['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7981f29",
   "metadata": {},
   "source": [
    "### División en train/test\n",
    "Dividimos los datos en conjunto de entrenamiento y prueba para evaluar la generalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fb3d91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8c2075",
   "metadata": {},
   "source": [
    "### Manejo clases desbalanceadas\n",
    "Si las clases están desbalanceadas, se aplica `SMOTE` para generar muestras sintéticas de la clase minoritaria solo en el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9887c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases balanceadas en train tras SMOTE: [4616 4616]\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "print(f\"Clases balanceadas en train tras SMOTE: {np.bincount(y_resampled)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481a36ef",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be25861",
   "metadata": {},
   "source": [
    "#### 1. GridSearchCV\n",
    "Se busca la mejor combinación de `C`, `gamma` y `kernel` para el modelo SVC, usando validación cruzada y priorizando el recall de la clase 0 (falsas).\n",
    "\n",
    "(En primer lugar he aplicado el gridSearch priorizando el accuaracy, luego lo he modificado para priorizar el f1-score de la clase 0 que era el  que peor resultados tenia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06a96e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1bc5ea07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros encontrados: {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "svc = SVC(class_weight='balanced')\n",
    "# Usar recall de clase 0\n",
    "scorer_recall_0 = make_scorer(recall_score, pos_label=0)\n",
    "grid_search = GridSearchCV(svc, param_grid, scoring=scorer_recall_0, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_resampled, y_resampled)\n",
    "print(f\"Mejores parámetros encontrados: {grid_search.best_params_}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1da975e",
   "metadata": {},
   "source": [
    "##### Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e5e3b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas en test:\n",
      "Accuracy: 0.6291\n",
      "Precision: 0.6799\n",
      "Recall: 0.8253\n",
      "F1-Score: 0.7456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.25      0.32       611\n",
      "           1       0.68      0.83      0.75      1179\n",
      "\n",
      "    accuracy                           0.63      1790\n",
      "   macro avg       0.55      0.54      0.53      1790\n",
      "weighted avg       0.59      0.63      0.60      1790\n",
      "\n",
      "[[153 458]\n",
      " [206 973]]\n"
     ]
    }
   ],
   "source": [
    "# Mejor modelo encontrado\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "print(\"Métricas en test:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e894debb",
   "metadata": {},
   "source": [
    "##### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "887cae74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission guardada en: C:/Users/inesg/dev/LBBYs_CH2/notebooks/3_summision/submission_grid_search_updated_1.csv\n"
     ]
    }
   ],
   "source": [
    "def encode_with_unknown_handling(le, series):\n",
    "    # Valores conocidos en train\n",
    "    known_labels = set(le.classes_)\n",
    "    # Reemplazar valores no conocidos por el más frecuente o un valor fijo\n",
    "    replacement = le.classes_[0]  # O el más frecuente en train\n",
    "    series_fixed = series.apply(lambda x: x if x in known_labels else replacement)\n",
    "    return le.transform(series_fixed)\n",
    "\n",
    "# Aplicar a cada columna categórica\n",
    "test_data['subject_encoded'] = encode_with_unknown_handling(label_encoder_subject, test_data['subject'])\n",
    "test_data['speaker_encoded'] = encode_with_unknown_handling(label_encoder_speaker, test_data['speaker'])\n",
    "test_data['party_affiliation_encoded'] = encode_with_unknown_handling(label_encoder_party, test_data['party_affiliation'])\n",
    "\n",
    "# Preprocesar texto test\n",
    "X_test_text = tokenizer.transform(test_data['statement']).toarray()\n",
    "\n",
    "# Codificar metadatos test\n",
    "test_data['state_info_encoded'] = test_data[state_info_columns].apply(\n",
    "    lambda x: 1 if any(isinstance(val, str) and len(val) > 0 for val in x) else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "X_test_metadata = test_data[['subject_encoded', 'speaker_encoded', 'state_info_encoded', 'party_affiliation_encoded']]\n",
    "\n",
    "# Escalar metadatos test\n",
    "X_test_metadata_scaled = scaler.transform(X_test_metadata)\n",
    "\n",
    "# Concatenar todo para obtener la matriz final con 1004 features\n",
    "X_test_final = np.concatenate([X_test_text, X_test_metadata_scaled], axis=1)\n",
    "\n",
    "# Predecir usando el modelo entrenado y matriz final\n",
    "y_pred_submission = best_model.predict(X_test_final)\n",
    "\n",
    "# Crear DataFrame submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_data['id'],\n",
    "    'label': y_pred_submission\n",
    "})\n",
    "\n",
    "submission_csv_path = f\"{submissions_folder}/submission_grid_search_updated_1.csv\"\n",
    "submission_df.to_csv(submission_csv_path, index=False)\n",
    "\n",
    "print(f\"Submission guardada en: {submission_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ba87bf",
   "metadata": {},
   "source": [
    "#### 2. SelectKBest\n",
    "Esta técnica selecciona las características más relevantes para la clasificación basándose en el análisis estadístico **ANOVA F-value**.\n",
    "\n",
    "Seleccionar solo las características más importantes puede ayudar a reducir ruido, mejorar el rendimiento y acelerar el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0acd2883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesg\\dev\\LBBYs_CH2\\venv\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: UserWarning: Features [1002] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\inesg\\dev\\LBBYs_CH2\\venv\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "selector = SelectKBest(f_classif, k=100)\n",
    "X_train_selected = selector.fit_transform(X_resampled, y_resampled)\n",
    "X_test_selected = selector.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4568f795",
   "metadata": {},
   "source": [
    "##### Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c7d1aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas con SelectKBest:\n",
      "Accuracy: 0.5642\n",
      "Precision: 0.7021\n",
      "Recall: 0.5878\n",
      "F1-Score: 0.6399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.52      0.45       611\n",
      "           1       0.70      0.59      0.64      1179\n",
      "\n",
      "    accuracy                           0.56      1790\n",
      "   macro avg       0.55      0.55      0.54      1790\n",
      "weighted avg       0.60      0.56      0.57      1790\n",
      "\n",
      "[[317 294]\n",
      " [486 693]]\n"
     ]
    }
   ],
   "source": [
    "svc_selected_model = SVC(C=10, gamma=1, kernel='rbf')\n",
    "svc_selected_model.fit(X_train_selected, y_resampled)\n",
    "\n",
    "y_pred_selectKBest = svc_selected_model.predict(X_test_selected)\n",
    "\n",
    "print(\"Métricas con SelectKBest:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_selectKBest):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_selectKBest):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_selectKBest):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_selectKBest):.4f}\")\n",
    "print(classification_report(y_test, y_pred_selectKBest))\n",
    "print(confusion_matrix(y_test, y_pred_selectKBest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee811121",
   "metadata": {},
   "source": [
    "##### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b0b25ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission guardada en: C:/Users/inesg/dev/LBBYs_CH2/notebooks/3_summision/submission_selectKBest.csv\n"
     ]
    }
   ],
   "source": [
    "# Preprocesar texto test\n",
    "X_test_text = tokenizer.transform(test_data['statement']).toarray()\n",
    "\n",
    "# Codificar metadatos test con manejo de valores desconocidos\n",
    "def encode_with_unknown_handling(le, series):\n",
    "    known_labels = set(le.classes_)\n",
    "    replacement = le.classes_[0]\n",
    "    series_fixed = series.apply(lambda x: x if x in known_labels else replacement)\n",
    "    return le.transform(series_fixed)\n",
    "\n",
    "test_data['subject_encoded'] = encode_with_unknown_handling(label_encoder_subject, test_data['subject'])\n",
    "test_data['speaker_encoded'] = encode_with_unknown_handling(label_encoder_speaker, test_data['speaker'])\n",
    "\n",
    "test_data['state_info_encoded'] = test_data[state_info_columns].apply(\n",
    "    lambda x: 1 if any(isinstance(val, str) and len(val) > 0 for val in x) else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "test_data['party_affiliation_encoded'] = encode_with_unknown_handling(label_encoder_party, test_data['party_affiliation'])\n",
    "\n",
    "X_test_metadata = test_data[['subject_encoded', 'speaker_encoded', 'state_info_encoded', 'party_affiliation_encoded']]\n",
    "\n",
    "# Escalar metadatos test\n",
    "X_test_metadata_scaled = scaler.transform(X_test_metadata)\n",
    "\n",
    "# Concatenar texto y metadatos\n",
    "X_test_final = np.concatenate([X_test_text, X_test_metadata_scaled], axis=1)\n",
    "\n",
    "# Aplicar SelectKBest al test\n",
    "X_test_selected = selector.transform(X_test_final)\n",
    "\n",
    "# Predecir con modelo entrenado\n",
    "y_pred_selectKBest_submission = svc_selected_model.predict(X_test_selected)\n",
    "\n",
    "# Crear DataFrame de submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_data['id'],\n",
    "    'label': y_pred_selectKBest_submission\n",
    "})\n",
    "\n",
    "# Guardar CSV\n",
    "submission_csv_path = f\"{submissions_folder}/submission_selectKBest.csv\"\n",
    "submission_df.to_csv(submission_csv_path, index=False)\n",
    "\n",
    "print(f\"Submission guardada en: {submission_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17670615",
   "metadata": {},
   "source": [
    "#### 3. RFE (Recursive Feature Elimination)\n",
    "\n",
    "RFE es una técnica que elimina recursivamente las características menos importantes basándose en la importancia que asigna un estimador (en este caso un SVC lineal).\n",
    "\n",
    "Se entrena un modelo con todas las características, se elimina la menos importante, y se repite hasta quedarse con el número deseado de características.\n",
    "\n",
    "Esto ayuda a obtener un subconjunto de características muy relevantes para mejorar la generalización y reducir ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a41b032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46783ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_base = SVC(kernel='linear', C=1)\n",
    "rfe_selector = RFE(estimator=svc_base, n_features_to_select=50)\n",
    "\n",
    "X_train_rfe = rfe_selector.fit_transform(X_resampled, y_resampled)\n",
    "\n",
    "X_test_rfe = rfe_selector.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eca16f",
   "metadata": {},
   "source": [
    "##### Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ede1796b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy con RFE: 0.5056\n",
      "Precision con RFE: 0.7466\n",
      "Recall con RFE: 0.3774\n",
      "F1-Score con RFE: 0.5014\n",
      "Reporte de clasificación con RFE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.75      0.51       611\n",
      "           1       0.75      0.38      0.50      1179\n",
      "\n",
      "    accuracy                           0.51      1790\n",
      "   macro avg       0.57      0.57      0.51      1790\n",
      "weighted avg       0.62      0.51      0.50      1790\n",
      "\n",
      "Matriz de confusión con RFE:\n",
      "[[460 151]\n",
      " [734 445]]\n"
     ]
    }
   ],
   "source": [
    "svc_rfe_model = SVC(C=10, gamma=1, kernel='rbf')\n",
    "svc_rfe_model.fit(X_train_rfe, y_resampled)\n",
    "\n",
    "y_pred_rfe = svc_rfe_model.predict(X_test_rfe)\n",
    "\n",
    "print(f\"Accuracy con RFE: {accuracy_score(y_test, y_pred_rfe):.4f}\")\n",
    "print(f\"Precision con RFE: {precision_score(y_test, y_pred_rfe):.4f}\")\n",
    "print(f\"Recall con RFE: {recall_score(y_test, y_pred_rfe):.4f}\")\n",
    "print(f\"F1-Score con RFE: {f1_score(y_test, y_pred_rfe):.4f}\")\n",
    "\n",
    "print(\"Reporte de clasificación con RFE:\")\n",
    "print(classification_report(y_test, y_pred_rfe))\n",
    "print(\"Matriz de confusión con RFE:\")\n",
    "print(confusion_matrix(y_test, y_pred_rfe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e33e630",
   "metadata": {},
   "source": [
    "##### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b606541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission guardada en: C:/Users/inesg/dev/LBBYs_CH2/notebooks/3_summision/submission_rfe.csv\n"
     ]
    }
   ],
   "source": [
    "# Preprocesar texto test\n",
    "X_test_text = tokenizer.transform(test_data['statement']).toarray()\n",
    "\n",
    "# Codificar metadatos test con manejo de valores desconocidos\n",
    "def encode_with_unknown_handling(le, series):\n",
    "    known_labels = set(le.classes_)\n",
    "    replacement = le.classes_[0]\n",
    "    series_fixed = series.apply(lambda x: x if x in known_labels else replacement)\n",
    "    return le.transform(series_fixed)\n",
    "\n",
    "test_data['subject_encoded'] = encode_with_unknown_handling(label_encoder_subject, test_data['subject'])\n",
    "test_data['speaker_encoded'] = encode_with_unknown_handling(label_encoder_speaker, test_data['speaker'])\n",
    "\n",
    "test_data['state_info_encoded'] = test_data[state_info_columns].apply(\n",
    "    lambda x: 1 if any(isinstance(val, str) and len(val) > 0 for val in x) else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "test_data['party_affiliation_encoded'] = encode_with_unknown_handling(label_encoder_party, test_data['party_affiliation'])\n",
    "\n",
    "X_test_metadata = test_data[['subject_encoded', 'speaker_encoded', 'state_info_encoded', 'party_affiliation_encoded']]\n",
    "\n",
    "# Escalar metadatos test\n",
    "X_test_metadata_scaled = scaler.transform(X_test_metadata)\n",
    "\n",
    "# Concatenar texto y metadatos\n",
    "X_test_final = np.concatenate([X_test_text, X_test_metadata_scaled], axis=1)\n",
    "\n",
    "# Aplicar RFE selector al test\n",
    "X_test_rfe = rfe_selector.transform(X_test_final)\n",
    "\n",
    "# Predecir con modelo entrenado\n",
    "y_pred_rfe_submission = svc_rfe_model.predict(X_test_rfe)\n",
    "\n",
    "# Crear DataFrame de submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_data['id'],\n",
    "    'label': y_pred_rfe_submission\n",
    "})\n",
    "\n",
    "# Guardar CSV\n",
    "submission_csv_path = f\"{submissions_folder}/submission_rfe.csv\"\n",
    "submission_df.to_csv(submission_csv_path, index=False)\n",
    "\n",
    "print(f\"Submission guardada en: {submission_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690505ca",
   "metadata": {},
   "source": [
    "# Conclusiones sobre las técnicas usadas en el modelo SVC para detección de noticias falsas\n",
    "\n",
    "## 1. GridSearchCV\n",
    "\n",
    "- GridSearchCV es una técnica que nos ayuda a encontrar la mejor combinación de hiperparámetros para el modelo. En este caso, buscábamos los valores óptimos para parámetros como `C`, `gamma` y el tipo de kernel en el SVC.\n",
    "- Primero intentamos optimizar el modelo para que tuviera la mejor precisión global (accuracy), pero noté que la clase 0 (noticias falsas) tenía resultados muy malos.\n",
    "- Entonces, cambié el enfoque para que GridSearch priorizara el f1-score de la clase 0, intentando mejorar la capacidad del modelo para detectar esas noticias falsas.\n",
    "- Finalmente, GridSearch indicó que la mejor configuración era: `C=10`, `gamma=1` y `kernel='rbf'`.\n",
    "- Con esos parámetros el modelo mejoró, pero todavía no detectaba bien la clase 0. Esto ocurre porque aunque GridSearch optimiza los parámetros, el modelo y los datos tienen limitaciones propias que no se solucionan solo con ajustar parámetros.\n",
    "\n",
    "## 2. SelectKBest\n",
    "\n",
    "- SelectKBest ayudó a reducir la dimensionalidad seleccionando las características más relevantes basadas en pruebas estadísticas.\n",
    "- Esto contribuyó a eliminar ruido y posibles variables poco informativas, mejorando la eficiencia del entrenamiento y la generalización del modelo.\n",
    "- Sin embargo, la mejora en métricas no fue muy destacable, lo que sugiere que el conjunto de características ya contenía cierta redundancia o que las características seleccionadas no capturaban suficientemente la complejidad del problema.\n",
    "- Además, al tratarse de un problema textual y semántico, la selección basada solo en criterios estadísticos simples puede no ser suficiente para identificar las verdaderas variables clave.\n",
    "\n",
    "## 3. RFE (Recursive Feature Elimination)\n",
    "\n",
    "- RFE se usó para eliminar recursivamente características menos importantes con el objetivo de mejorar el rendimiento del modelo y evitar sobreajuste.\n",
    "- Esta técnica permitió identificar un subconjunto más pequeño de variables, simplificando el modelo y potencialmente mejorando su interpretabilidad.\n",
    "- A pesar de esto, las métricas, especialmente para la clase minoritaria, no mejoraron significativamente, evidenciando que el problema principal no es solo el exceso de características, sino la dificultad del dataset y la representación de la información.\n",
    "- RFE con un modelo SVC lineal puede ser demasiado restrictivo para un problema tan complejo como la detección de noticias falsas, donde las relaciones entre variables pueden ser no lineales y de alta dimensión.\n",
    "\n",
    "---\n",
    "\n",
    "### Resumen general\n",
    "\n",
    "Cada técnica contribuyó de alguna forma a mejorar el modelo o su interpretación, pero ninguna por sí sola logró resolver los principales desafíos del problema:\n",
    "\n",
    "- GridSearchCV afinó hiperparámetros pero no pudo compensar las limitaciones del modelo y los datos.  \n",
    "- SelectKBest y RFE ayudaron a reducir características irrelevantes, pero no lograron mejorar la detección de la clase minoritaria.  \n",
    "\n",
    "Esto indica que para mejorar los resultados sería necesario combinar estas técnicas con:\n",
    "\n",
    "- Representaciones más avanzadas del texto.  \n",
    "- Modelos más potentes y flexibles que puedan capturar patrones complejos.  \n",
    "- Métodos más robustos para manejar el desbalance y la ambigüedad en las etiquetas.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
