{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bacfb4b-550c-4c13-b283-784db14e1c9d",
   "metadata": {},
   "source": [
    "# Red Neuronal Convolucional (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07bfd01-9c1e-4920-8eb9-a38e2d70ddba",
   "metadata": {},
   "source": [
    "###  Introducción\n",
    "\n",
    "En este trabajo se implementa una red neuronal convolucional (CNN) para clasificar declaraciones políticas a partir de texto y variables categóricas adicionales. Se utiliza la columna `statement` como entrada principal, procesada mediante tokenización y padding, mientras que variables como `speaker`, `party_affiliation` y `subject` se codifican con one-hot encoding. El objetivo es combinar información textual y estructurada para mejorar la precisión del modelo en la tarea de clasificación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b452a3-5b7d-4483-8be5-182d1dd694fd",
   "metadata": {},
   "source": [
    "## 1. Carga de librerías\n",
    "Se importan las librerías necesarias para el procesamiento de datos, codificación de variables, evaluación del modelo y construcción de una red neuronal convolucional (CNN) con Keras y TensorFlow. También se incluyen herramientas para tokenización, secuenciación de texto y regularización del entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "71a60dfb-9814-4f97-b4f2-9b4698822794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849db4e7-91fb-49be-9443-889742a1c73b",
   "metadata": {},
   "source": [
    "## 2. Carga y exploración del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de105c1f-932a-4a82-88e8-72c2c83f7c15",
   "metadata": {},
   "source": [
    "Se cargaron los conjuntos de datos de entrenamiento y prueba desde archivos CSV previamente preprocesados. A continuación, se preparó la entrada textual utilizando la columna `statement`, que se tokenizó con un vocabulario máximo de 20,000 palabras y se transformó en secuencias numéricas, ajustadas a una longitud fija de 100 tokens mediante padding. Esta representación es necesaria para alimentar correctamente las secuencias a la red neuronal.\n",
    "\n",
    "Simultáneamente, se seleccionaron varias columnas categóricas relevantes (`subject`, `speaker`, `party_affiliation`, entre otras) que fueron transformadas mediante codificación one-hot. Estas variables no textuales complementan la información lingüística del texto y permiten al modelo capturar contexto estructurado.\n",
    "\n",
    "Finalmente, se dividió el conjunto de entrenamiento en entrenamiento y validación (80/20) y se calcularon los pesos de clase para abordar cualquier desequilibrio en las etiquetas. Se definió un modelo CNN mejorado que combina convoluciones 1D sobre el texto con una red densa para las variables categóricas. Las salidas de ambos flujos se concatenan y pasan por capas densas con regularización y dropout. El modelo se compila usando el optimizador Adam, pérdida binaria y métrica de precisión, listo para ser entrenado en tareas de clasificación binaria.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "20f380d3-3d0a-4d0a-8c61-760402834cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r\"C:\\Users\\Day\\Documents\\LBBYs_CH2-ana\\LBBYs_CH2-ana\\data\\processed\\train_preprocess_v1.csv\")\n",
    "test_df = pd.read_csv(r\"C:\\Users\\Day\\Documents\\LBBYs_CH2-ana\\LBBYs_CH2-ana\\data\\processed\\test_preprocess_v1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "842bc200-7c94-47fa-b20e-cfb045e92192",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB = 20000\n",
    "MAX_LEN = 100\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB)\n",
    "tokenizer.fit_on_texts(train_df['statement'])\n",
    "\n",
    "X_train_text = tokenizer.texts_to_sequences(train_df['statement'])\n",
    "X_train_text = pad_sequences(X_train_text, maxlen=MAX_LEN)\n",
    "\n",
    "X_test_text = tokenizer.texts_to_sequences(test_df['statement'])\n",
    "X_test_text = pad_sequences(X_test_text, maxlen=MAX_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "db9e4297-3b23-46b2-8991-3ff69e303ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = [\n",
    "    'subject', 'speaker', 'speaker_job', 'state_info',\n",
    "    'party_affiliation', 'party_affiliation_uni', 'party_affiliation_category_map',\n",
    "    'processed_subject', 'speaker_type'\n",
    "]\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "X_train_cats = encoder.fit_transform(train_df[cat_columns])\n",
    "X_test_cats = encoder.transform(test_df[cat_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "770b3585-d752-4f2c-8ba0-31fcca4a213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text, X_val_text, X_train_cats, X_val_cats, y_train, y_val = train_test_split(\n",
    "    X_train_text, X_train_cats, train_df['label'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3de6b863-d69d-4d4c-9cbe-02e7aa41f6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_array = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = dict(enumerate(class_weights_array))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8ae23ec0-b965-4d51-8914-38420e6967f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_improved_cnn_model_with_features():\n",
    "    input_text = Input(shape=(MAX_LEN,), name='text_input')\n",
    "    x = Embedding(input_dim=MAX_VOCAB, output_dim=EMBEDDING_DIM, embeddings_regularizer=l2(1e-6))(input_text)\n",
    "\n",
    "    convs = []\n",
    "    for size in [3, 4, 5]:\n",
    "        c = Conv1D(256, size, activation='relu')(x)\n",
    "        c = GlobalMaxPooling1D()(c)\n",
    "        convs.append(c)\n",
    "    x_text = Concatenate()(convs)\n",
    "    x_text = Dropout(0.5)(x_text)\n",
    "\n",
    "    input_cats = Input(shape=(X_train_cats.shape[1],), name='cats_input')\n",
    "    x_cats = Dense(64, activation='relu', kernel_regularizer=l2(1e-4))(input_cats)\n",
    "    x_cats = Dropout(0.3)(x_cats)\n",
    "\n",
    "    x = Concatenate()([x_text, x_cats])\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=l2(1e-4))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=[input_text, input_cats], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57406cd-bc2e-435b-b849-52bb9d5dca41",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento del modelo KNN\n",
    "\n",
    "Se entrenó el modelo CNN combinando texto y variables categóricas, utilizando validación interna, pesos de clase balanceados y early stopping para evitar sobreajuste. El entrenamiento se realizó durante un máximo de 30 épocas con un tamaño de lote de 32.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "94a1b5d4-51bb-43f6-8e38-fc7d2b31989b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 100ms/step - accuracy: 0.4717 - loss: 0.7249 - val_accuracy: 0.5235 - val_loss: 0.7170\n",
      "Epoch 2/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 91ms/step - accuracy: 0.5409 - loss: 0.7123 - val_accuracy: 0.6240 - val_loss: 0.6917\n",
      "Epoch 3/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 95ms/step - accuracy: 0.6291 - loss: 0.6906 - val_accuracy: 0.5849 - val_loss: 0.6930\n",
      "Epoch 4/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 90ms/step - accuracy: 0.6532 - loss: 0.6580 - val_accuracy: 0.5905 - val_loss: 0.6792\n",
      "Epoch 5/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 96ms/step - accuracy: 0.6960 - loss: 0.6230 - val_accuracy: 0.5983 - val_loss: 0.6776\n",
      "Epoch 6/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 88ms/step - accuracy: 0.7668 - loss: 0.5524 - val_accuracy: 0.5966 - val_loss: 0.6853\n",
      "Epoch 7/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 89ms/step - accuracy: 0.8142 - loss: 0.4856 - val_accuracy: 0.6056 - val_loss: 0.6844\n",
      "Epoch 8/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 96ms/step - accuracy: 0.8660 - loss: 0.4039 - val_accuracy: 0.6190 - val_loss: 0.6944\n",
      "Epoch 9/30\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 91ms/step - accuracy: 0.9099 - loss: 0.3106 - val_accuracy: 0.6168 - val_loss: 0.7336\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step\n"
     ]
    }
   ],
   "source": [
    "model = build_improved_cnn_model_with_features()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "\n",
    "history = model.fit([X_train_text, X_train_cats],\n",
    "                    y_train,\n",
    "                    validation_data=([X_val_text, X_val_cats], y_val),\n",
    "                    epochs=30,\n",
    "                    batch_size=32,\n",
    "                    class_weight=class_weights_dict,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "y_val_probs = model.predict([X_val_text, X_val_cats])\n",
    "y_val_pred = (y_val_probs > 0.5).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3cc2a5-94cb-4f66-b13e-70c04e792e54",
   "metadata": {},
   "source": [
    "## 4. Evaluación del modelo\n",
    "\n",
    "Con el modelo CNN definido y entrenado, se realizan predicciones sobre el conjunto de validación. Se imprime un reporte de clasificación que incluye precisión, recall y F1-score para cada clase, además de métricas promedio y exactitud general.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c9c9d05b-f8aa-4d44-871b-341c2e8b554f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de métricas en VALIDACIÓN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.61      0.51       611\n",
      "           1       0.74      0.59      0.66      1179\n",
      "\n",
      "    accuracy                           0.60      1790\n",
      "   macro avg       0.59      0.60      0.58      1790\n",
      "weighted avg       0.64      0.60      0.61      1790\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Reporte de métricas en VALIDACIÓN:\")\n",
    "print(classification_report(y_val, y_val_pred, digits=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42391025-7af4-4dfe-8d80-6ab0063ea348",
   "metadata": {},
   "source": [
    "## 5. Generación de predicciones para test\n",
    "\n",
    "Finalmente, se generan predicciones sobre el conjunto de prueba utilizando el mejor modelo entrenado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7e5e2e2a-9c41-477b-9fc2-743e0f1a1052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_probs = model.predict([X_test_text, X_test_cats])\n",
    "y_test_pred = (y_test_probs > 0.5).astype(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c970c10-3a76-41c1-aa3b-3a325592f18b",
   "metadata": {},
   "source": [
    "## 6. Exportar predicciones\n",
    "Los resultados se guardan en un archivo `.csv` para su envío o análisis posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "20d233bf-940b-4d58-b1e3-42107350514a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones guardadas en 'predicciones_finales_mejoradas.csv'\n"
     ]
    }
   ],
   "source": [
    "predictions = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'label': y_test_pred.flatten()\n",
    "})\n",
    "\n",
    "predictions.to_csv(\"CNN_16.csv\", index=False)\n",
    "print(\"Predicciones guardadas en 'predicciones_finales_mejoradas.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b374363a-d7ff-4a20-9cef-4845a0a247ab",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4524eb01-3f71-47ea-b385-a340c8e7ca44",
   "metadata": {},
   "source": [
    "El modelo CNN alcanzó una precisión general del 61 % en el conjunto de validación. Este resultado refleja un desempeño moderado al clasificar correctamente los ejemplos de ambas clases, aunque con margen para mejoras. La red fue capaz de captar patrones tanto del texto como de las variables categóricas utilizadas como entrada combinada.\n",
    "\n",
    "En cuanto al desempeño por clase, la clase 0 obtuvo un F1-score de 0.52 con un recall de 0.61, indicando que el modelo logró identificar una buena parte de los ejemplos reales de esa clase, aunque con una precisión algo baja (0.45). Por su parte, la clase 1 alcanzó una precisión notable (0.75), pero un recall más bajo (0.61), lo que sugiere que el modelo fue más conservador al predecir esta clase, priorizando exactitud sobre cobertura.\n",
    "\n",
    "En general, el modelo muestra un equilibrio razonable entre precisión y recall, especialmente en un escenario con clases desbalanceadas. Las métricas macro y ponderadas (F1-score de 0.59 y 0.62 respectivamente) indican que el modelo puede ser una base sólida para mejoras futuras, ya sea ajustando la arquitectura, afinando hiperparámetros o incorporando más datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2555a90d-2cbf-4647-ae3f-8ce117666ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fake_news_env]",
   "language": "python",
   "name": "conda-env-fake_news_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
