{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a89f0f4-8fbe-43fd-983a-2f0c5d770930",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55465e33-4f36-4d82-8d9b-70c47cb014c4",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "En este proyecto se aplica el algoritmo de clasificación K-Nearest Neighbors (KNN) para predecir la veracidad de afirmaciones (statements) basadas en información textual y categórica asociada, como el tema, el autor, su ocupación y afiliación política.\n",
    "\n",
    "El enfoque combina técnicas de procesamiento de texto (TF-IDF) con codificación categórica para construir un conjunto de características robusto. Se utiliza validación cruzada y búsqueda de hiperparámetros para optimizar el modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4856ffc-4ca3-4e7d-b34a-d97f55a6d2d8",
   "metadata": {},
   "source": [
    "## 1. Carga de librerías\n",
    "Se importan las bibliotecas necesarias para manipulación de datos, vectorización de texto, codificación de variables categóricas, entrenamiento del modelo y evaluación de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e8e253a-c6eb-4d89-9551-c5c029981612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b93320-b652-4808-9b75-6978a023fc39",
   "metadata": {},
   "source": [
    "## 2. Carga y exploración del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dd6e18-45a2-4090-9b42-d4bc3bb2d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "train_df = pd.read_csv('../../../data/processed/train_preprocess_v1.csv')\n",
    "test_df = pd.read_csv('../../../data/processed/test_preprocess_v1.csv')\n",
    "\n",
    "# Preprocesamiento: seleccionar las columnas relevantes\n",
    "X_train_full = train_df[['statement', 'subject', 'speaker', 'speaker_job', 'party_affiliation', \n",
    "                         'party_affiliation_uni', 'party_affiliation_category_map']]\n",
    "y_train = train_df['label']\n",
    "\n",
    "X_test_full = test_df[['statement', 'subject', 'speaker', 'speaker_job', 'party_affiliation', \n",
    "                       'party_affiliation_uni', 'party_affiliation_category_map']]\n",
    "\n",
    "# Vectorización de los textos con TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)  # Limitar el número de características para reducir la dimensionalidad\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_full['statement'])\n",
    "X_test_tfidf = vectorizer.transform(X_test_full['statement'])\n",
    "\n",
    "# Para las características no textuales, usamos OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')  # Manejar categorías desconocidas con 'ignore'\n",
    "X_train_additional = encoder.fit_transform(X_train_full[['subject', 'speaker', 'speaker_job', \n",
    "                                                        'party_affiliation', 'party_affiliation_uni', \n",
    "                                                        'party_affiliation_category_map']])\n",
    "X_test_additional = encoder.transform(X_test_full[['subject', 'speaker', 'speaker_job', \n",
    "                                                   'party_affiliation', 'party_affiliation_uni', \n",
    "                                                   'party_affiliation_category_map']])\n",
    "\n",
    "# Concatenar las características textuales y no textuales\n",
    "X_train_final = np.hstack([X_train_tfidf.toarray(), X_train_additional])\n",
    "X_test_final = np.hstack([X_test_tfidf.toarray(), X_test_additional])\n",
    "\n",
    "# Dividir el conjunto de datos de entrenamiento en entrenamiento y validación (80/20)\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_final, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffad7161-7875-4aad-9e28-4d63a86de370",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento del modelo KNN\n",
    "\n",
    "Se entrena un clasificador KNN utilizando validación cruzada (3-fold) y búsqueda en malla (GridSearchCV) para encontrar los mejores hiperparámetros: número de vecinos (`n_neighbors`), métrica de distancia y tipo de ponderación.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b47f434-91bc-4eaa-b46f-e1c0c29e7334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "# Definir el clasificador KNN y los parámetros para GridSearch\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'metric': ['euclidean', 'manhattan'],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros con validación cruzada\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=3, scoring='accuracy', verbose=10, n_jobs=-1)\n",
    "grid_search.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Mostrar el mejor conjunto de parámetros\n",
    "print(f\"Mejores parámetros encontrados: {grid_search.best_params_}\")\n",
    "\n",
    "# Usar el mejor modelo para hacer predicciones\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "# Predicciones en el conjunto de validación\n",
    "y_val_pred = best_knn.predict(X_val_split)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dbdd5f-8088-43af-822b-f227e10f789a",
   "metadata": {},
   "source": [
    "## 4. Evaluación del modelo\n",
    "\n",
    "Con el mejor modelo encontrado por GridSearchCV, se hacen predicciones sobre el conjunto de validación. Se imprime un reporte de clasificación con precisión, recall y F1-score para cada clase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c44539-adff-4f37-bd79-a3bd03f3776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar el reporte de clasificación\n",
    "print(\"Classification Report para Validación:\")\n",
    "print(classification_report(y_val_split, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b07bf8-c99a-4f8a-9b33-bd31e7b2464e",
   "metadata": {},
   "source": [
    "## 5. Generación de predicciones para test\n",
    "\n",
    "Finalmente, se generan predicciones sobre el conjunto de prueba utilizando el mejor modelo entrenado. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96807f6-956f-453f-9293-f922a4a07c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones en el conjunto de test\n",
    "y_test_pred = best_knn.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c1cc3d-52c5-448d-be8e-211971f9ee55",
   "metadata": {},
   "source": [
    "## 6. Exportar predicciones\n",
    "Los resultados se guardan en un archivo `.csv` para su envío o análisis posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49348e0b-b493-4632-b46b-428c56ca4129",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Guardar las predicciones en el formato adecuado\n",
    "predictions = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'label': y_test_pred\n",
    "})\n",
    "\n",
    "predictions.to_csv(\"prediction27.csv\", index=False)\n",
    "print(\"Predicciones guardadas en 'predictions.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e8b72a-da47-49d5-8d77-2ca20ca95709",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48b3a81-3871-49da-a3bb-6d7371af8417",
   "metadata": {},
   "source": [
    "Para entrenar el modelo KNN, se definió un clasificador y se realizó una búsqueda exhaustiva de hiperparámetros utilizando GridSearchCV. Se exploraron distintas combinaciones de número de vecinos (3, 5, 7, 9, 11), métricas de distancia (euclidiana y Manhattan) y métodos de ponderación (uniforme y por distancia), con una validación cruzada de 3 folds. Este enfoque permitió identificar el mejor conjunto de parámetros basado en la métrica de exactitud, resultando en una configuración óptima con 11 vecinos, distancia euclidiana y ponderación por distancia.\n",
    "\n",
    "El rendimiento del modelo en el conjunto de validación mostró una exactitud global del 64%, con un desempeño desigual entre las clases. La clase 1 fue detectada con buena precisión y recall, lo que indica que el modelo clasifica correctamente la mayoría de sus casos. En contraste, la clase 0 presentó una precisión y recall bajos, reflejando dificultades para identificarla adecuadamente. Esto sugiere un posible desequilibrio en las clases o diferencias en la complejidad para clasificarlas, afectando la capacidad del modelo para generalizar en la clase menos representada o más compleja.\n",
    "\n",
    "Como próximos pasos, sería recomendable explorar técnicas para mejorar la detección de la clase con menor desempeño, tales como ajustar pesos para equilibrar las clases o aplicar métodos de sobremuestreo. Además, probar otros valores de vecinos y métricas distintas podría ayudar a optimizar aún más el modelo. Finalmente, considerar preprocesamientos adicionales o modelos alternativos puede ser útil para superar las limitaciones actuales y lograr un mejor balance en la clasificación."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fake_news_env]",
   "language": "python",
   "name": "conda-env-fake_news_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
